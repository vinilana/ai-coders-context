# @ai-coders/context â€” Full Guide

A CLI that scaffolds living documentation and AI-agent playbooks for any repository. The generated structure gives teams a consistent starting point for knowledge sharing while keeping everything under version control.

## What You Get

- ðŸ“š `docs/` folder with documentation guides (overview, architecture, workflow, testing)
- ðŸ¤– `agents/` folder with playbooks for engineering agents
- âš¡ Semantic analysis using Tree-sitter for efficient LLM calls
- ðŸ”Œ MCP Server for Claude Code integration
- ðŸ”— Passthrough mode for external AI agents

## Installation

```bash
# Run directly with npx (recommended)
npx @ai-coders/context

# Or install as dev dependency
npm install --save-dev @ai-coders/context
```

## Interactive Mode

Just run without arguments:

```bash
npx @ai-coders/context
```

The wizard will:
1. Detect your project state
2. Offer appropriate actions (init, fill, update, plan)
3. Guide you through configuration

## Commands

### `init` â€” Create Documentation Structure

```bash
npx @ai-coders/context init ./my-repo          # Both docs and agents
npx @ai-coders/context init ./my-repo docs     # Only docs
npx @ai-coders/context init ./my-repo agents   # Only agents
```

**Options:**
- `-o, --output <dir>` â€” Output directory (default: `./.context`)
- `--exclude <patterns...>` â€” Glob patterns to skip
- `--include <patterns...>` â€” Glob patterns to include
- `--no-semantic` â€” Disable semantic analysis
- `-v, --verbose` â€” Detailed output

### `fill` â€” Populate with AI

```bash
npx @ai-coders/context fill ./my-repo
npx @ai-coders/context fill ./my-repo --provider anthropic
npx @ai-coders/context fill ./my-repo --limit 3  # Preview first 3
```

**Options:**
- `-k, --api-key <key>` â€” API key for LLM provider
- `-m, --model <model>` â€” Model to use
- `-p, --provider <name>` â€” Provider (openrouter, openai, anthropic, google)
- `--base-url <url>` â€” Custom API base URL
- `--prompt <file>` â€” Custom instruction prompt
- `--limit <number>` â€” Max files to update
- `--no-semantic` â€” Use tool-based exploration
- `--languages <langs>` â€” Languages to analyze (e.g., typescript,python)
- `-v, --verbose` â€” Detailed output

### `update` â€” Refresh Outdated Docs

```bash
npx @ai-coders/context update              # Analyze and update
npx @ai-coders/context update --dry-run    # Preview only
npx @ai-coders/context update --days 7     # Look back 7 days
```

**Options:**
- `--days <number>` â€” Days to look back (default: 30)
- `--dry-run` â€” Show what would be updated
- `--no-git` â€” Use mtime instead of git
- Same LLM options as `fill`

### `plan` â€” Create Work Plans

```bash
npx @ai-coders/context plan release-readiness
npx @ai-coders/context plan feature-auth --fill  # Fill with LLM
```

**Options:**
- `--title <title>` â€” Custom title
- `--summary <text>` â€” Goal statement
- `-f, --force` â€” Overwrite existing plan
- `--fill` â€” Use LLM to populate
- `--dry-run` â€” Preview changes
- Same LLM options as `fill`

### `mcp` â€” Claude Code Server

```bash
npx @ai-coders/context mcp -r ./my-project
```

See [MCP.md](./MCP.md) for integration details.

### `serve` â€” External Agent Server

```bash
npx @ai-coders/context serve -r ./my-project
echo '{"id":"1","method":"capabilities"}' | npx @ai-coders/context serve
```

## Semantic Context Mode

By default, `fill` uses semantic analysis with Tree-sitter:

- **Faster** â€” Single LLM call instead of multi-step exploration
- **Efficient** â€” Pre-computed context reduces tokens
- **Consistent** â€” Same analysis for all files

Disable with `--no-semantic` for more thorough exploration.

### Supported Languages

`typescript`, `javascript`, `python`, `go`, `rust`, `java`, `cpp`, `c_sharp`, `ruby`, `php`

Specify with `--languages`:
```bash
npx @ai-coders/context fill . --languages typescript,python
```

### Optional LSP Enhancement

For deeper analysis, enable LSP integration:

```bash
npx @ai-coders/context fill . --use-lsp
```

LSP provides type inference, interface implementations, and cross-file references. Requires language servers:
- TypeScript/JavaScript: `typescript-language-server`
- Python: `pylsp`

## Doc Guides & Agent Types

**Docs:** project-overview, architecture, development-workflow, testing-strategy, glossary, data-flow, security, tooling

**Agents:** code-reviewer, bug-fixer, feature-developer, refactoring-specialist, test-writer, documentation-writer, performance-optimizer, security-auditor, backend-specialist, frontend-specialist, architect-specialist

## Output Structure

```
.context/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ code-reviewer.md
â”‚   â””â”€â”€ ...
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ architecture.md
â”‚   â””â”€â”€ ...
â””â”€â”€ plans/
    â””â”€â”€ README.md
```

## Environment Variables

```bash
# Provider selection
AI_CONTEXT_PROVIDER=openrouter|openai|anthropic|google

# API Keys
OPENROUTER_API_KEY=...
OPENAI_API_KEY=...
ANTHROPIC_API_KEY=...
GOOGLE_API_KEY=...

# Model override
OPENROUTER_MODEL=x-ai/grok-4-fast
OPENAI_MODEL=gpt-4o
ANTHROPIC_MODEL=claude-sonnet-4-20250514
GOOGLE_MODEL=gemini-2.0-flash

# CLI settings
AI_CONTEXT_LANG=en|pt-BR
AI_CONTEXT_DISABLE_UPDATE_CHECK=true
```

## Local Development

```bash
git clone https://github.com/vinilana/ai-coders-context.git
cd ai-coders-context
npm install
npm run build
npm run test
npm run dev -- ./path/to/repo  # Run against TypeScript sources
```
